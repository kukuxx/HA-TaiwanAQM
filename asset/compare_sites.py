"""
æ¯”å°ç’°ä¿ç½²ç©ºæ°£å“è³ªç›£æ¸¬ç«™é»è³‡æ–™
"""
import json
import csv
import sys
import os
import subprocess

from typing import List, Dict, Set, Tuple
from datetime import datetime

import requests

class SiteComparator:
    def __init__(self, api_url: str, expected_file: str):
        self.api_url = api_url
        self.expected_file = expected_file
        self.api_sites: Set[Tuple[str, str, str]] = set()
        self.expected_sites: Set[Tuple[str, str, str]] = set()

    def fetch_api_data(self) -> None:
        """å¾ API ä¸‹è¼‰ CSV è³‡æ–™ä¸¦è§£æ"""
        print("ğŸ“¡ æ­£åœ¨ä¸‹è¼‰ API è³‡æ–™...")
        try:
            response = requests.get(self.api_url, timeout=30, verify=False)
            response.raise_for_status()
            
            # è™•ç† BOM
            content = response.content.decode('utf-8-sig')
                
            csv_reader = csv.DictReader(content.splitlines())
            for row in csv_reader:
                siteid = row.get('siteid', '').strip()
                sitename = row.get('sitename', '').strip()
                county = row.get('county', '').strip()
                
                if siteid and sitename and county:
                    self.api_sites.add((siteid, sitename, county))
            
            print(f"âœ… æˆåŠŸå–å¾— {len(self.api_sites)} å€‹ç«™é»")
        except requests.exceptions.RequestException as e:
            print(f"âŒ ä¸‹è¼‰ API è³‡æ–™å¤±æ•—: {e}", file=sys.stderr)
            sys.exit(1)
        except Exception as e:
            print(f"âŒ è™•ç†è³‡æ–™å¤±æ•—: {e}", file=sys.stderr)
            sys.exit(1)

    def load_expected_data(self) -> None:
        """è¼‰å…¥é æœŸçš„ç«™é»è³‡æ–™"""
        print("ğŸ“‚ æ­£åœ¨è¼‰å…¥é æœŸç«™é»è³‡æ–™...")
        try:
            with open(self.expected_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            for site in data:
                siteid = str(site.get('siteid', '')).strip()
                sitename = site.get('sitename', '').strip()
                county = site.get('county', '').strip()
                
                if siteid and sitename and county:
                    self.expected_sites.add((siteid, sitename, county))
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.expected_sites)} å€‹é æœŸç«™é»")
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {self.expected_file}", file=sys.stderr)
            sys.exit(1)
        except json.JSONDecodeError as e:
            print(f"âŒ JSON æ ¼å¼éŒ¯èª¤: {e}", file=sys.stderr)
            sys.exit(1)

    def compare(self) -> Tuple[List[Dict], List[Dict]]:
        """æ¯”å°ç«™é»å·®ç•°"""
        print("ğŸ” æ­£åœ¨æ¯”å°ç«™é»...")
        
        new_sites = self.api_sites - self.expected_sites
        removed_sites = self.expected_sites - self.api_sites
        
        new_sites_list = [
            {'siteid': s[0], 'sitename': s[1], 'county': s[2]}
            for s in sorted(new_sites, key=lambda x: x[0])
        ]
        
        removed_sites_list = [
            {'siteid': s[0], 'sitename': s[1], 'county': s[2]}
            for s in sorted(removed_sites, key=lambda x: x[0])
        ]
        
        return new_sites_list, removed_sites_list

    def generate_report(self, new_sites: List[Dict], removed_sites: List[Dict]) -> Dict:
        """ç”Ÿæˆæ¯”å°å ±å‘Š"""
        report = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'has_changes': bool(new_sites or removed_sites),
            'statistics': {
                'api_total': len(self.api_sites),
                'expected_total': len(self.expected_sites),
                'new_count': len(new_sites),
                'removed_count': len(removed_sites)
            },
            'new_sites': new_sites,
            'removed_sites': removed_sites
        }
        return report

    def print_summary(self, report: Dict) -> None:
        """è¼¸å‡ºæ‘˜è¦åˆ°çµ‚ç«¯"""
        print("\n" + "="*60)
        print(f"ğŸ“Š æ¯”å°çµæœæ‘˜è¦ ({report['timestamp']})")
        print("="*60)
        print(f"API ç«™é»ç¸½æ•¸: {report['statistics']['api_total']}")
        print(f"é æœŸç«™é»ç¸½æ•¸: {report['statistics']['expected_total']}")
        print(f"æ–°å¢ç«™é»æ•¸: {report['statistics']['new_count']}")
        print(f"ç§»é™¤ç«™é»æ•¸: {report['statistics']['removed_count']}")
        
        if report['new_sites']:
            print("\nğŸ†• æ–°å¢ç«™é»:")
            for site in report['new_sites']:
                print(f"  - {site['siteid']}: {site['sitename']} ({site['county']})")
        
        if report['removed_sites']:
            print("\nâŒ ç§»é™¤ç«™é»:")
            for site in report['removed_sites']:
                print(f"  - {site['siteid']}: {site['sitename']} ({site['county']})")
        
        if not report['has_changes']:
            print("\nâœ… ç„¡ç«™é»è®Šæ›´")
        
        print("="*60)

    def generate_github_summary(self, report: Dict) -> None:
        """ç”Ÿæˆ GitHub Actions Summary"""
        summary_file = os.environ.get('GITHUB_STEP_SUMMARY')
        if not summary_file:
            print("âš ï¸ é GitHub Actions ç’°å¢ƒ,è·³é Summary ç”Ÿæˆ")
            return
        
        print("ğŸ“ æ­£åœ¨ç”Ÿæˆ GitHub Summary...")
        
        with open(summary_file, 'a', encoding='utf-8') as f:
            f.write("## ğŸ” ç«™é»è®Šæ›´æª¢æŸ¥çµæœ\n\n")
            f.write(f"**æª¢æŸ¥æ™‚é–“:** {report['timestamp']}\n\n")
            
            if report['has_changes']:
                f.write("### âš ï¸ åµæ¸¬åˆ°ç«™é»è®Šæ›´\n\n")
                
                if report['new_sites']:
                    f.write("#### ğŸ†• æ–°å¢ç«™é»:\n\n")
                    for site in report['new_sites']:
                        f.write(f"- **{site['siteid']}**: {site['sitename']} ({site['county']})\n")
                    f.write("\n")
                
                if report['removed_sites']:
                    f.write("#### âŒ ç§»é™¤ç«™é»:\n\n")
                    for site in report['removed_sites']:
                        f.write(f"- **{site['siteid']}**: {site['sitename']} ({site['county']})\n")
                    f.write("\n")
            else:
                f.write("### âœ… ç„¡ç«™é»è®Šæ›´\n\n")
                f.write("æ‰€æœ‰ç«™é»èˆ‡é æœŸç›¸ç¬¦,æœªåµæ¸¬åˆ°ä»»ä½•è®Šæ›´ã€‚\n\n")
            
            f.write("---\n\n")
            f.write("ğŸ“Š **çµ±è¨ˆè³‡è¨Š:**\n\n")
            f.write(f"- API å›å‚³ç«™é»æ•¸: {report['statistics']['api_total']}\n")
            f.write(f"- é æœŸç«™é»æ•¸: {report['statistics']['expected_total']}\n")
            f.write(f"- æ–°å¢ç«™é»æ•¸: {report['statistics']['new_count']}\n")
            f.write(f"- ç§»é™¤ç«™é»æ•¸: {report['statistics']['removed_count']}\n")
        
        print("âœ… GitHub Summary å·²ç”Ÿæˆ")

    def create_or_update_issue(self, report: Dict) -> None:
        """å»ºç«‹æˆ–æ›´æ–° GitHub Issue"""
        if not report['has_changes']:
            print("âœ… ç„¡è®Šæ›´,ä¸éœ€è¦å»ºç«‹ Issue")
            return
        
        gh_token = os.environ.get('GH_TOKEN') or os.environ.get('GITHUB_TOKEN')
        if not gh_token:
            print("âš ï¸ æ‰¾ä¸åˆ° GitHub Token,è·³é Issue å»ºç«‹")
            return
        
        print("ğŸ”” æ­£åœ¨è™•ç† GitHub Issue...")
        
        # å»ºç«‹ Issue Body
        body = "ğŸš¨ Changes detected in Site list:\n\n"
        
        if report['new_sites']:
            body += "### ğŸ†• New Sites:\n\n"
            for site in report['new_sites']:
                body += f"- {site['siteid']}: {site['sitename']} ({site['county']})\n"
            body += "\n"
        
        if report['removed_sites']:
            body += "### âŒ Removed Sites:\n\n"
            for site in report['removed_sites']:
                body += f"- {site['siteid']}: {site['sitename']} ({site['county']})\n"
            body += "\n"
        
        body += f"---\n\n**æª¢æŸ¥æ™‚é–“:** {report['timestamp']}\n"
        
        try:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒæ¨™ç±¤çš„ Issue
            result = subprocess.run(
                ['gh', 'issue', 'list', '--state', 'open', '--label', 'site change', '--json', 'number'],
                capture_output=True,
                text=True,
                check=True
            )
            
            issues = json.loads(result.stdout)
            
            if issues:
                issue_number = issues[0]['number']
                print(f"âœï¸ æ›´æ–°ç¾æœ‰ Issue: #{issue_number}")
                subprocess.run(
                    ['gh', 'issue', 'edit', str(issue_number), '--body', body],
                    check=True
                )
            else:
                print("ğŸ†• å»ºç«‹æ–° Issue")
                subprocess.run(
                    ['gh', 'issue', 'create', '--title', 'Site change', '--body', body, '--label', 'site change'],
                    check=True
                )
            
            print("âœ… Issue è™•ç†å®Œæˆ")
        except subprocess.CalledProcessError as e:
            print(f"âŒ è™•ç† Issue å¤±æ•—: {e}", file=sys.stderr)
        except FileNotFoundError:
            print("âŒ æ‰¾ä¸åˆ° gh æŒ‡ä»¤,è«‹ç¢ºèªå·²å®‰è£ GitHub CLI", file=sys.stderr)

    def run(self) -> Dict:
        """åŸ·è¡Œå®Œæ•´çš„æ¯”å°æµç¨‹"""
        self.fetch_api_data()
        self.load_expected_data()
        new_sites, removed_sites = self.compare()
        report = self.generate_report(new_sites, removed_sites)
        self.print_summary(report)
        self.generate_github_summary(report)
        self.create_or_update_issue(report)
        return report


def main():
    api_url = "https://data.moenv.gov.tw/api/v2/aqx_p_432?api_key=e75b1660-e564-4107-aad5-a8be1f905dd9&limit=1000&sort=ImportDate%20desc&format=CSV"
    
    expected_file = "asset/expected_sites.json"
    
    comparator = SiteComparator(api_url, expected_file)
    report = comparator.run()
    
    if report['has_changes']:
        print("\nâš ï¸ åµæ¸¬åˆ°è®Šæ›´")
        sys.exit(0)
    else:
        print("\nâœ… ç„¡è®Šæ›´")
        sys.exit(0)


if __name__ == "__main__":
    main()